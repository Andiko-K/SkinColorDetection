# -*- coding: utf-8 -*-
"""Tone Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10pfrLCfJahJkT6cetNHpwTnCXQoXi8n1
"""

# https://drive.google.com/file/d/1qAgLKmiIJr3YGklhSHv277_QBFOhdnJP/view?usp=sharing
# !wget wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1qAgLKmiIJr3YGklhSHv277_QBFOhdnJP' -O tonedataset.zip
!gdown 1qAgLKmiIJr3YGklhSHv277_QBFOhdnJP

pip install tensorflow

pip install patool

import patoolib
patoolib.extract_archive("mst_dataset.rar", outdir="./mst_dataset")

import os

tone_1 = os.path.join('./mst_dataset/Tone 1')
tone_2 = os.path.join('./mst_dataset/Tone 2')
tone_3 = os.path.join('./mst_dataset/Tone 3')
tone_4 = os.path.join('./mst_dataset/Tone 4')
tone_5 = os.path.join('./mst_dataset/Tone 5')
tone_6 = os.path.join('./mst_dataset/Tone 6')
tone_7 = os.path.join('./mst_dataset/Tone 7')
tone_8 = os.path.join('./mst_dataset/Tone 8')
tone_9 = os.path.join('./mst_dataset/Tone 9')
tone_10 = os.path.join('./mst_dataset/Tone 10')

tone_1_img = os.listdir(tone_1)
print(tone_1_img[:10])
tone_2_img = os.listdir(tone_2)
print(tone_2_img[:10])

# Create Train and Val

import shutil
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile

# Define root directory
root_dir = './dataset'

# Empty directory to prevent FileExistsError is the function is run several times
if os.path.exists(root_dir):
  shutil.rmtree(root_dir)

def create_train_val_dirs(root_path):
  """
  Creates directories for the train and test sets

  Args:
    root_path (string) - the base directory path to create subdirectories from

  Returns:
    None
  """
  training = os.path.join(root_dir, 'training')
  validation = os.path.join(root_dir, 'validation')


  training_1 = os.path.join(training, 'tone_1')
  training_2 = os.path.join(training, 'tone_2')
  training_3 = os.path.join(training, 'tone_3')
  training_4 = os.path.join(training, 'tone_4')
  training_5 = os.path.join(training, 'tone_5')
  training_6 = os.path.join(training, 'tone_6')
  training_7 = os.path.join(training, 'tone_7')
  training_8 = os.path.join(training, 'tone_8')
  training_9 = os.path.join(training, 'tone_9')
  training_10 = os.path.join(training, 'tone_10')

  validation_1 = os.path.join(validation, 'tone_1')
  validation_2 = os.path.join(validation, 'tone_2')
  validation_3 = os.path.join(validation, 'tone_3')
  validation_4 = os.path.join(validation, 'tone_4')
  validation_5 = os.path.join(validation, 'tone_5')
  validation_6 = os.path.join(validation, 'tone_6')
  validation_7 = os.path.join(validation, 'tone_7')
  validation_8 = os.path.join(validation, 'tone_8')
  validation_9 = os.path.join(validation, 'tone_9')
  validation_10 = os.path.join(validation, 'tone_10')

  # for x in range(6):


  os.makedirs(training)
  os.makedirs(validation)
  os.makedirs(training_1)
  os.makedirs(training_2)
  os.makedirs(training_3)
  os.makedirs(training_4)
  os.makedirs(training_5)
  os.makedirs(training_6)
  os.makedirs(training_7)
  os.makedirs(training_8)
  os.makedirs(training_9)
  os.makedirs(training_10)


  os.makedirs(validation_1)
  os.makedirs(validation_2)
  os.makedirs(validation_3)
  os.makedirs(validation_4)
  os.makedirs(validation_5)
  os.makedirs(validation_6)
  os.makedirs(validation_7)
  os.makedirs(validation_8)
  os.makedirs(validation_9)
  os.makedirs(validation_10)

  print(os.listdir(training))
  pass


try:
  create_train_val_dirs(root_path=root_dir)
except FileExistsError:
  print("You should not be seeing this since the upper directory is removed beforehand")

for rootdir, dirs, files in os.walk(root_dir):
    for subdir in dirs:
        print(os.path.join(rootdir, subdir))

import random

# GRADED FUNCTION: split_data
def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):
  """
  Splits the data into train and test sets

  Args:
    SOURCE_DIR (string): directory path containing the images
    TRAINING_DIR (string): directory path to be used for training
    VALIDATION_DIR (string): directory path to be used for validation
    SPLIT_SIZE (float): proportion of the dataset to be used for training

  Returns:
    None
  """
  # train_cats_dir =  os.path.join(TRAINING_DIR,)
  ### START CODE HERE
  data = []
  for file_name in os.listdir(SOURCE_DIR):
        file_path = SOURCE_DIR + file_name

        if os.path.getsize(file_path):
            data.append(file_name)
        else:
            print('{} is zero length, so ignoring'.format(file_name))

  # data = os.listdir(SOURCE_DIR)
  data = random.sample(data, len(data))

  train_size = int(len(data)*SPLIT_SIZE)

  train = data[0:train_size]
  validation = data[train_size:]

  for file_name in train:
        copyfile(SOURCE_DIR + file_name, TRAINING_DIR + file_name)
  for file_name in validation:
        copyfile(SOURCE_DIR + file_name, VALIDATION_DIR + file_name)
  # print(os.listdir(SOURCE_DIR))

  # train_cat_fnames = os.listdir( TRAINING_DIR )
  # random.sample(train_cat_fnames, len(train_cat_fnames))
  # print(train_cat_fnames[:10])
  pass


  ### END CODE HERE

# Test your split_data function

# Define paths
tone_1 = "./mst_dataset/Tone 1/"
tone_2 = "./mst_dataset/Tone 2/"
tone_3 = "./mst_dataset/Tone 3/"
tone_4 = "./mst_dataset/Tone 4/"
tone_5 = "./mst_dataset/Tone 5/"
tone_6 = "./mst_dataset/Tone 6/"
tone_7 = "./mst_dataset/Tone 7/"
tone_8 = "./mst_dataset/Tone 8/"
tone_9 = "./mst_dataset/Tone 9/"
tone_10 = "./mst_dataset/Tone 10/"

TRAINING_DIR = "./dataset/training/"
VALIDATION_DIR = "./dataset/validation/"

# training_tone1 = os.path.join(TRAINING_DIR, "tone1/")
# validation_tone1 = os.path.join(VALIDATION_DIR, "tone1/")

# training_tone2 = os.path.join(TRAINING_DIR, "tone2/")
# validation_tone2 = os.path.join(VALIDATION_DIR, "tone2/")

# training_tone2 = os.path.join(TRAINING_DIR, "tone2/")
# validation_tone2 = os.path.join(VALIDATION_DIR, "tone2/")

training_tone1 = os.path.join(TRAINING_DIR, "tone_1/")
validation_tone1 = os.path.join(VALIDATION_DIR, "tone_1/")

training_tone2 = os.path.join(TRAINING_DIR, "tone_2/")
validation_tone2 = os.path.join(VALIDATION_DIR, "tone_2/")

training_tone3 = os.path.join(TRAINING_DIR, "tone_3/")
validation_tone3 = os.path.join(VALIDATION_DIR, "tone_3/")

training_tone4 = os.path.join(TRAINING_DIR, "tone_4/")
validation_tone4 = os.path.join(VALIDATION_DIR, "tone_4/")

training_tone5 = os.path.join(TRAINING_DIR, "tone_5/")
validation_tone5 = os.path.join(VALIDATION_DIR, "tone_5/")

training_tone6 = os.path.join(TRAINING_DIR, "tone_6/")
validation_tone6 = os.path.join(VALIDATION_DIR, "tone_6/")

training_tone7 = os.path.join(TRAINING_DIR, "tone_7/")
validation_tone7 = os.path.join(VALIDATION_DIR, "tone_7/")

training_tone8 = os.path.join(TRAINING_DIR, "tone_8/")
validation_tone8 = os.path.join(VALIDATION_DIR, "tone_8/")

training_tone9 = os.path.join(TRAINING_DIR, "tone_9/")
validation_tone9 = os.path.join(VALIDATION_DIR, "tone_9/")

training_tone10 = os.path.join(TRAINING_DIR, "tone_10/")
validation_tone10 = os.path.join(VALIDATION_DIR, "tone_10/")


# Empty directories in case you run this cell multiple times
# if len(os.listdir(TRAINING_CATS_DIR)) > 0:
#   for file in os.scandir(TRAINING_CATS_DIR):
#     os.remove(file.path)
# if len(os.listdir(TRAINING_DOGS_DIR)) > 0:
#   for file in os.scandir(TRAINING_DOGS_DIR):
#     os.remove(file.path)
# if len(os.listdir(VALIDATION_CATS_DIR)) > 0:
#   for file in os.scandir(VALIDATION_CATS_DIR):
#     os.remove(file.path)
# if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:
#   for file in os.scandir(VALIDATION_DOGS_DIR):
#     os.remove(file.path)

if len(os.listdir(training_tone1)) > 0:
  for file in os.scandir(training_tone1):
    os.remove(file.path)
if len(os.listdir(validation_tone1)) > 0:
  for file in os.scandir(validation_tone1):
    os.remove(file.path)

if len(os.listdir(training_tone2)) > 0:
  for file in os.scandir(training_tone2):
    os.remove(file.path)
if len(os.listdir(validation_tone2)) > 0:
  for file in os.scandir(validation_tone2):
    os.remove(file.path)

if len(os.listdir(training_tone3)) > 0:
  for file in os.scandir(training_tone3):
    os.remove(file.path)
if len(os.listdir(validation_tone3)) > 0:
  for file in os.scandir(validation_tone3):
    os.remove(file.path)

if len(os.listdir(training_tone4)) > 0:
  for file in os.scandir(training_tone4):
    os.remove(file.path)
if len(os.listdir(validation_tone4)) > 0:
  for file in os.scandir(validation_tone4):
    os.remove(file.path)

if len(os.listdir(training_tone5)) > 0:
  for file in os.scandir(training_tone5):
    os.remove(file.path)
if len(os.listdir(validation_tone5)) > 0:
  for file in os.scandir(validation_tone5):
    os.remove(file.path)

if len(os.listdir(training_tone6)) > 0:
  for file in os.scandir(training_tone6):
    os.remove(file.path)
if len(os.listdir(validation_tone6)) > 0:
  for file in os.scandir(validation_tone6):
    os.remove(file.path)

if len(os.listdir(training_tone7)) > 0:
  for file in os.scandir(training_tone7):
    os.remove(file.path)
if len(os.listdir(validation_tone7)) > 0:
  for file in os.scandir(validation_tone7):
    os.remove(file.path)

if len(os.listdir(training_tone8)) > 0:
  for file in os.scandir(training_tone8):
    os.remove(file.path)
if len(os.listdir(validation_tone8)) > 0:
  for file in os.scandir(validation_tone8):
    os.remove(file.path)

if len(os.listdir(training_tone9)) > 0:
  for file in os.scandir(training_tone9):
    os.remove(file.path)
if len(os.listdir(validation_tone9)) > 0:
  for file in os.scandir(validation_tone9):
    os.remove(file.path)

if len(os.listdir(training_tone10)) > 0:
  for file in os.scandir(training_tone10):
    os.remove(file.path)
if len(os.listdir(validation_tone10)) > 0:
  for file in os.scandir(validation_tone10):
    os.remove(file.path)


# Define proportion of images used for training
split_size = .9

# Run the function
# NOTE: Messages about zero length images should be printed out
split_data(tone_1, training_tone1, validation_tone1, split_size)
split_data(tone_2, training_tone2, validation_tone2, split_size)
split_data(tone_3, training_tone3, validation_tone3, split_size)
split_data(tone_4, training_tone4, validation_tone4, split_size)
split_data(tone_5, training_tone5, validation_tone5, split_size)
split_data(tone_6, training_tone6, validation_tone6, split_size)
split_data(tone_7, training_tone7, validation_tone7, split_size)
split_data(tone_8, training_tone8, validation_tone8, split_size)
split_data(tone_9, training_tone9, validation_tone9, split_size)
split_data(tone_10, training_tone10, validation_tone10, split_size)


# Check that the number of images matches the expected output

# Your function should perform copies rather than moving images so original directories should contain unchanged images
print(f"\n\nOriginal tone1 directory has {len(os.listdir(tone_1))} images")
print(f"Original tone2 directory has {len(os.listdir(tone_2))} images\n")

# Training and validation splits
print(f"There are {len(os.listdir(training_tone1))} images of tone1 for training")
print(f"There are {len(os.listdir(training_tone2))} images of tone2 for training")
print(f"There are {len(os.listdir(validation_tone1))} images of tone1 for validation")
print(f"There are {len(os.listdir(validation_tone2))} images of tone1 for validation")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def train_val_generators(TRAINING_DIR, VALIDATION_DIR):
  """
  Creates the training and validation data generators

  Args:
    TRAINING_DIR (string): directory path containing the training images
    VALIDATION_DIR (string): directory path containing the testing/validation images

  Returns:
    train_generator, validation_generator - tuple containing the generators
  """

  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)
  train_datagen = ImageDataGenerator( rescale = 1.0/255. )

  # Pass in the appropriate arguments to the flow_from_directory method
  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,
                                                      batch_size=64,
                                                      class_mode='binary',
                                                      target_size=(576, 768))

  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)
  validation_datagen = ImageDataGenerator( rescale = 1.0/255. )

  # Pass in the appropriate arguments to the flow_from_directory method
  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,
                                                                batch_size=64,
                                                                class_mode='binary',
                                                                target_size=(576, 768))
  return train_generator, validation_generator

train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)

import tensorflow as tf

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 300x300 with 3 bytes color
    # This is the first convolution
    # tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(576, 768, 3)),
    # tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fifth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')
    tf.keras.layers.Dense(10, activation='softmax')
])

# model.summary()

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=RMSprop(learning_rate=0.001),
              metrics=['accuracy'])

history = model.fit(train_generator,
                    epochs=15,
                    verbose=1,
                    validation_data=validation_generator)

import numpy as np
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = '/content/' + fn
  img = load_img(path, target_size=(576, 768))
  x = img_to_array(img)
  x /= 255
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(classes)


  # if classes[0]>0.5:
  #   print(fn + " is a tone2")
  # else:
  #   print(fn + " is a tone1")

model.save("tone_model.h5")

pip install pyyaml h5py

import os

new_model = tf.keras.models.load_model('tone_model.h5')

uploaded = files.upload()

for fn in uploaded.keys():

  mapping = {
      'tone 1':0,
      'tone 2':1,
      'tone 3':2,
      'tone 4':3,
      'tone 5':4,
      'tone 6':5,
      'tone 7':6,
      'tone 8':7,
      'tone 9':8,
      'tone 10':9,
  }

  # predicting images
  path = '/content/' + fn
  image = tf.io.read_file(path)
  image = tf.image.decode_png (image, channels=3)
  image = tf.image.convert_image_dtype(image, dtype=tf.float32)
  image = tf.image.resize(image, [576,768])
  image = tf.expand_dims(image, axis=0)
  # (60,60,3) tf.expand_dims(image, axis=0) # (1,60,60,3) image image = = image = image image =
  # img = load_img(path, target_size=(576, 768))
  # x = img_to_array(img)
  # x /= 255
  # x = np.expand_dims(x, axis=0)

  # images = np.vstack([x])

  classes = model.predict(image, batch_size=10)
  print(classes[0])
  prediction = np.argmax(classes[0])
  print(prediction)
  # print(list(mapping.values()).index(prediction))

  # Tone 1 = 0
  # Tone 2 = 2
  # Tone 10 = 1